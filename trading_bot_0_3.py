# trading_bot_optimized_v2.0.0.py
# Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø© - Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø£Ù‚ÙˆÙ‰ ÙˆØ£Ø°ÙƒÙ‰ ğŸš€
# Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª: pip install ccxt fastapi uvicorn pandas requests ta

import os, json, asyncio, time, io, csv, sqlite3, random, math, traceback
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timezone

import requests
import pandas as pd
import ccxt
from fastapi import FastAPI
import uvicorn

# ========================== [ ENV ] ==========================
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN", "").strip()
CHAT_ID        = os.getenv("CHAT_ID", "").strip()

EXCHANGE_ENV   = os.getenv("EXCHANGE", "").strip().lower()
SYMBOLS_ENV    = os.getenv("SYMBOLS", "").strip()
TIMEFRAME_ENV  = os.getenv("TIMEFRAME", "").strip()

# ========================== [ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø­Ø³Ù‘Ù†Ø© ] ==========================
EXCHANGE_NAME = EXCHANGE_ENV or "okx"
TIMEFRAME     = TIMEFRAME_ENV or "5m"
SYMBOLS_MODE  = SYMBOLS_ENV or "ALL"

# âœ¨ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙÙ„ØªØ±Ø© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø© - Ø£ÙƒØ«Ø± Ø°ÙƒØ§Ø¡Ù‹
MIN_CONFIDENCE         = 48  # Ø®ÙÙ‘Ø¶Ù†Ø§ Ø§Ù„Ø­Ø¯ Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ÙØ±Øµ
MIN_ATR_PCT            = 0.08  # Ù‚Ø¨ÙˆÙ„ ØªÙ‚Ù„Ø¨Ø§Øª Ø£Ù‚Ù„
MIN_AVG_VOL_USDT       = 30_000  # Ø­Ø¬Ù… Ø£Ù‚Ù„ Ù„Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ÙØ±Øµ

# Ù†Ø·Ø§Ù‚Ø§Øª RSI Ù…Ø­Ø³Ù‘Ù†Ø© Ù„ØµÙŠØ¯ Ø§Ù„ÙØ±Øµ Ø§Ù„Ø°Ù‡Ø¨ÙŠØ©
RSI_LONG_MIN,  RSI_LONG_MAX  = 35, 75  # Ù†Ø·Ø§Ù‚ Ø£ÙˆØ³Ø¹
RSI_SHORT_MIN, RSI_SHORT_MAX = 25, 65

# Bollinger Bands - Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø©
BB_BANDWIDTH_MAX       = 0.055  # Ù‚Ø¨ÙˆÙ„ Ø§Ù†Ø¶ØºØ§Ø·Ø§Øª Ø£ÙˆØ³Ø¹ Ù‚Ù„ÙŠÙ„Ø§Ù‹
BB_BANDWIDTH_MAX_SOFT  = 0.10
ALLOW_NO_SQUEEZE       = True

REQUIRE_TREND          = False  # Ù†ØªØ¯Ø§ÙˆÙ„ Ù…Ø¹ ÙˆØ¶Ø¯ Ø§Ù„ØªØ±Ù†Ø¯

# âœ¨ Ø£Ù‡Ø¯Ø§Ù ÙˆØ³ØªÙˆØ¨ Ø£ÙØ¶Ù„ - Ù†Ø³Ø¨ Ø±Ø¨Ø­/Ø®Ø³Ø§Ø±Ø© Ù…Ø­Ø³Ù‘Ù†Ø©
TP_PCTS                = [0.4, 0.8, 1.4, 2.2]  # Ø£Ù‡Ø¯Ø§Ù Ø£Ù‚Ø±Ø¨ ÙˆØ£ÙƒØ«Ø± ÙˆØ§Ù‚Ø¹ÙŠØ©
ATR_SL_MULT            = 2.2  # Ø³ØªÙˆØ¨ Ø£ÙˆØ³Ø¹ Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø§Ù‡ØªØ²Ø§Ø²Ø§Øª
SL_LOOKBACK            = 18  # Ù†Ø¸Ø±Ø© Ø£Ø¹Ù…Ù‚ Ù„Ù„Ø³ÙˆÙŠÙ†ØºØ§Øª
MIN_SL_PCT, MAX_SL_PCT = 0.25, 2.5  # Ø³ØªÙˆØ¨ Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø©

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø³Ø­
SCAN_INTERVAL                 = 45  # Ù…Ø³Ø­ Ø£Ø³Ø±Ø¹
MIN_SIGNAL_GAP_SEC            = 4
MAX_ALERTS_PER_CYCLE          = 10  # Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª
COOLDOWN_PER_SYMBOL_CANDLES   = 6  # ÙƒÙˆÙ„Ø¯Ø§ÙˆÙ† Ø£Ù‚ØµØ±
MAX_SYMBOLS                   = 150  # Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø£Ø²ÙˆØ§Ø¬

NO_SIG_EVERY_N_CYCLES         = 0
NO_SIG_EVERY_MINUTES          = 0

KEEPALIVE_URL      = ""
KEEPALIVE_INTERVAL = 240

BUILD_UTC     = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M UTC")
APP_VERSION   = f"2.0.0-OPTIMIZED ({BUILD_UTC})"
POLL_COMMANDS = True
POLL_INTERVAL = 10

LOG_DB_PATH = "bot_stats.db"

if not TELEGRAM_TOKEN or not CHAT_ID:
    raise SystemExit("ENV Ù…ÙÙ‚ÙˆØ¯Ø©: TELEGRAM_TOKEN Ùˆ CHAT_ID Ù…Ø·Ù„ÙˆØ¨Ø©.")

TG_API   = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}"
SEND_URL = TG_API + "/sendMessage"
DOC_URL  = TG_API + "/sendDocument"
TG_GET_UPDATES    = TG_API + "/getUpdates"
TG_DELETE_WEBHOOK = TG_API + "/deleteWebhook"

_last_send_ts = 0
_error_bucket = []
_error_last_flush = 0
ERROR_FLUSH_EVERY = 300

def _reply_kb(rows: List[List[str]]) -> str:
    return json.dumps({
        "keyboard":[[{"text":t} for t in row] for row in rows],
        "resize_keyboard": True,
        "is_persistent": True
    })

def send_telegram(text: str, reply_to_message_id: Optional[int]=None,
                  reply_markup: Optional[str]=None) -> Optional[int]:
    global _last_send_ts
    now = time.time()
    if now - _last_send_ts < MIN_SIGNAL_GAP_SEC:
        time.sleep(max(0, MIN_SIGNAL_GAP_SEC - (now - _last_send_ts)))
    data = {"chat_id": CHAT_ID, "text": text, "disable_web_page_preview": True}
    if reply_to_message_id: data["reply_to_message_id"] = reply_to_message_id
    if reply_markup: data["reply_markup"] = reply_markup
    try:
        r = requests.post(SEND_URL, data=data, timeout=25).json()
        if not r.get("ok"):
            print("Telegram error:", r)
            return None
        _last_send_ts = time.time()
        return r["result"]["message_id"]
    except Exception as e:
        print("Telegram send error:", e)
        return None

def send_document(filename: str, file_bytes: bytes, caption: str="") -> bool:
    try:
        files={"document":(filename, io.BytesIO(file_bytes))}
        data={"chat_id": CHAT_ID, "caption": caption}
        r=requests.post(DOC_URL, data=data, files=files, timeout=60).json()
        if not r.get("ok"): print("send_document error:", r); return False
        return True
    except Exception as e:
        print("send_document exception:", e); return False

def start_menu_markup() -> str:
    return _reply_kb([
        ["ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª", "ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…"],
        ["ğŸ“„ Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨", "ğŸ“œ Ø¢Ø®Ø± Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª"],
        ["ğŸ“Œ Ø§Ù„Ù…ÙØªÙˆØ­Ø©", "â¬‡ï¸ ØªØµØ¯ÙŠØ± CSV"],
        ["ğŸ“‹ ØªØµØ¯ÙŠØ± ØªØ­Ù„ÙŠÙ„ÙŠ", "ğŸ” ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©"]
    ])

def send_start_menu():
    send_telegram("Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:", reply_markup=start_menu_markup())

# ================== Ù…Ø¤Ø´Ø±Ø§Øª Ù…Ø­Ø³Ù‘Ù†Ø© ==================
def ema(s: pd.Series, n:int)->pd.Series: 
    return s.ewm(span=n, adjust=False).mean()

def rsi(s: pd.Series, n=14)->pd.Series:
    d=s.diff()
    up=d.clip(lower=0)
    dn=-d.clip(upper=0)
    ma_up=up.ewm(com=n-1, adjust=False).mean()
    ma_dn=dn.ewm(com=n-1, adjust=False).mean()
    rs=ma_up/(ma_dn.replace(0,1e-12))
    return 100-(100/(1+rs))

def macd(s: pd.Series, f=12, sl=26, sig=9)->Tuple[pd.Series,pd.Series]:
    ef, es = ema(s,f), ema(s,sl)
    line=ef-es
    return line, ema(line,sig)

def bollinger(s: pd.Series, n=20, k=2.0):
    ma=s.rolling(n).mean()
    sd=s.rolling(n).std(ddof=0)
    up=ma+k*sd
    dn=ma-k*sd
    bw=(up-dn)/ma.replace(0, 1e-12)
    return ma, up, dn, bw

def atr(df: pd.DataFrame, n=14):
    h,l,c = df["high"], df["low"], df["close"]
    tr=pd.concat([(h-l).abs(),(h-c.shift()).abs(),(l-c.shift()).abs()],axis=1).max(axis=1)
    return tr.ewm(alpha=1/n, adjust=False).mean()

# âœ¨ Ù…Ø¤Ø´Ø± Ø¬Ø¯ÙŠØ¯: Stochastic Ù„Ù„Ø²Ø®Ù…
def stochastic(df: pd.DataFrame, k_period=14, d_period=3):
    high = df["high"]
    low = df["low"]
    close = df["close"]
    
    lowest_low = low.rolling(window=k_period).min()
    highest_high = high.rolling(window=k_period).max()
    
    k = 100 * (close - lowest_low) / (highest_high - lowest_low).replace(0, 1e-12)
    d = k.rolling(window=d_period).mean()
    
    return k, d

# âœ¨ Ù…Ø¤Ø´Ø± Ø¬Ø¯ÙŠØ¯: ADX Ù„Ù„Ù‚ÙˆØ©
def adx(df: pd.DataFrame, period=14):
    high = df["high"]
    low = df["low"]
    close = df["close"]
    
    plus_dm = high.diff()
    minus_dm = -low.diff()
    
    plus_dm[plus_dm < 0] = 0
    minus_dm[minus_dm < 0] = 0
    
    tr = atr(df, 1)
    atr_period = tr.rolling(window=period).mean()
    
    plus_di = 100 * (plus_dm.rolling(window=period).mean() / atr_period)
    minus_di = 100 * (minus_dm.rolling(window=period).mean() / atr_period)
    
    dx = 100 * abs(plus_di - minus_di) / (plus_di + minus_di).replace(0, 1e-12)
    adx_val = dx.rolling(window=period).mean()
    
    return adx_val, plus_di, minus_di

def clamp(x,a,b): 
    return max(a, min(b,x))

# ================== CCXT & Symbols ==================
EXC={"bybit":ccxt.bybit,"okx":ccxt.okx,"kucoinfutures":ccxt.kucoinfutures,"bitget":ccxt.bitget,
     "gate":ccxt.gate,"binance":ccxt.binance,"krakenfutures":ccxt.krakenfutures}

def make_exchange(name:str):
    klass=EXC.get(name, ccxt.okx)
    cfg={"enableRateLimit":True,"timeout":20000,
         "options":{"defaultType":"swap","defaultSubType":"linear"}}
    return klass(cfg)

def load_markets_linear_only(ex):
    last=None
    for i,b in enumerate([1.5,3,6],1):
        try: 
            ex.load_markets(reload=True, params={"category":"linear","type":"swap"})
            return
        except Exception as e:
            last=e
            print(f"[load_markets {i}] {type(e).__name__}: {str(e)[:160]}")
            time.sleep(b)
    raise last

def try_failover(primary:str)->Tuple[ccxt.Exchange,str]:
    last=None
    for name in [primary,"okx","kucoinfutures","bitget","gate","binance"]:
        try:
            ex=make_exchange(name)
            load_markets_linear_only(ex)
            return ex,name
        except Exception as e:
            last=e
            print("[failover]", name, "failed:", type(e).__name__, str(e)[:100])
    raise last or SystemExit("No exchange available.")

def normalize_symbols_for_exchange(ex, syms:List[str])->List[str]:
    if ex.id=="bybit":
        return [s + (":USDT" if s.endswith("/USDT") and ":USDT" not in s else "") for s in syms]
    return syms

def list_all_futures_symbols(ex)->List[str]:
    syms=[]
    for m in ex.markets.values():
        if m.get("contract") and (m.get("swap") or m.get("future")) and m.get("active",True) is not False:
            syms.append(m["symbol"])
    syms=sorted(set(syms))
    if MAX_SYMBOLS>0: 
        syms=syms[:MAX_SYMBOLS]
    return normalize_symbols_for_exchange(ex, syms)

def parse_symbols(ex, val:str)->List[str]:
    key=(val or "").strip().upper()
    if key in ("ALL","AUTO_FUTURES","AUTO","AUTO_SWAP","AUTO_LINEAR"):
        return list_all_futures_symbols(ex)
    syms=[s.strip() for s in (val or "").split(",") if s.strip()]
    syms=normalize_symbols_for_exchange(ex, syms)
    if MAX_SYMBOLS>0: 
        syms=syms[:MAX_SYMBOLS]
    return syms

# ================== Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ==================
async def fetch_ohlcv_safe(ex, symbol:str, timeframe:str, limit:int):
    try:
        params={}
        if ex.id=="bybit": 
            params={"category":"linear"}
        elif ex.id=="okx": 
            params={"instType":"SWAP"}
        
        ohlcv=await asyncio.to_thread(ex.fetch_ohlcv, symbol, timeframe=timeframe, limit=limit, params=params)
        
        if not ohlcv or len(ohlcv)<60: 
            return None
        
        df=pd.DataFrame(ohlcv, columns=["ts","open","high","low","close","volume"])
        df["ts"]=pd.to_datetime(df["ts"], unit="ms", utc=True)
        df.set_index("ts", inplace=True)
        return df
    except Exception as e:
        return f"Ø®Ø·Ø£ Ø§Ù„Ù…Ù†ØµØ©: {ex.id} {type(e).__name__} {str(e)[:200]}"

async def fetch_ticker_price(ex, symbol:str)->Optional[float]:
    try:
        t=await asyncio.to_thread(ex.fetch_ticker, symbol)
        v=t.get("last") or t.get("close") or t.get("info",{}).get("lastPrice")
        return float(v) if v is not None else None
    except Exception: 
        return None

# ================== DB/Helpers ==================
def unix_now()->int: 
    return int(datetime.now(timezone.utc).timestamp())

def symbol_pretty(s:str)->str: 
    return s.replace(":USDT","")

open_trades: Dict[str,Dict]={}
signal_state: Dict[str,Dict]={}
_last_cycle_alerts=0

def db_conn(): 
    con=sqlite3.connect(LOG_DB_PATH)
    con.execute("PRAGMA journal_mode=WAL;")
    return con

def db_init():
    con=db_conn()
    con.execute("""CREATE TABLE IF NOT EXISTS signals(
      id INTEGER PRIMARY KEY AUTOINCREMENT, ts INTEGER, exchange TEXT, symbol TEXT,
      side TEXT, entry REAL, sl REAL, tp1 REAL, tp2 REAL, tp3 REAL, tp4 REAL, confidence INTEGER, msg_id INTEGER);""")
    con.execute("""CREATE TABLE IF NOT EXISTS outcomes(
      id INTEGER PRIMARY KEY AUTOINCREMENT, signal_id INTEGER, ts INTEGER, event TEXT, idx INTEGER, price REAL);""")
    con.execute("""CREATE TABLE IF NOT EXISTS nosignal_reasons(
      id INTEGER PRIMARY KEY AUTOINCREMENT, ts INTEGER, exchange TEXT, symbol TEXT, reasons TEXT);""")
    con.execute("""CREATE TABLE IF NOT EXISTS errors(
      id INTEGER PRIMARY KEY AUTOINCREMENT, ts INTEGER, exchange TEXT, symbol TEXT, message TEXT);""")
    con.commit()
    con.close()

def db_insert_signal(ts,ex,sym,side,entry,sl,tps,conf,msg_id)->int:
    con=db_conn()
    cur=con.cursor()
    cur.execute("INSERT INTO signals(ts,exchange,symbol,side,entry,sl,tp1,tp2,tp3,tp4,confidence,msg_id) VALUES(?,?,?,?,?,?,?,?,?,?,?,?)",
                (ts,ex,sym,side,entry,sl,tps[0],tps[1],tps[2],tps[3],conf,msg_id))
    con.commit()
    sid=cur.lastrowid
    con.close()
    return sid

def db_insert_outcome(signal_id,ts,event,idx,price):
    con=db_conn()
    con.execute("INSERT INTO outcomes(signal_id,ts,event,idx,price) VALUES(?,?,?,?,?)",
                (signal_id,ts,event,idx,price))
    con.commit()
    con.close()

def db_insert_nosignal(ts,ex,sym,rsn:Dict):
    con=db_conn()
    con.execute("INSERT INTO nosignal_reasons(ts,exchange,symbol,reasons) VALUES(?,?,?,?)",
                (ts,ex,sym,json.dumps(rsn,ensure_ascii=False)))
    con.commit()
    con.close()

def db_insert_error(ts,ex,sym,msg):
    con=db_conn()
    con.execute("INSERT INTO errors(ts,exchange,symbol,message) VALUES(?,?,?,?)",
                (ts,ex,sym,msg))
    con.commit()
    con.close()

# ================== âœ¨ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø© ÙˆØ§Ù„Ø¬Ø¨Ø§Ø±Ø© ==================
def _f(x)->float:
    v=float(x)
    if math.isnan(v) or math.isinf(v): 
        raise ValueError("nan/inf")
    return v

def compute_confidence_advanced(side:str, bw_now:float, c_prev:float, c_now:float, 
                                band_now:float, macd_now:float, macd_sig:float, 
                                r14:float, atr_now:float, stoch_k:float, stoch_d:float,
                                adx_val:float, plus_di:float, minus_di:float,
                                volume_ratio:float)->int:
    """
    Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ù…Ø­Ø³Ù‘Ù† Ù…Ø¹ Ù…Ø¤Ø´Ø±Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
    """
    # 1. Ø§Ù†Ø¶ØºØ§Ø· Ø§Ù„Ø¨ÙˆÙ„ÙŠÙ†Ø¬Ø± (ÙƒÙ„Ù…Ø§ Ø£Ù‚Ù„ ÙƒÙ„Ù…Ø§ Ø£ÙØ¶Ù„)
    tight = clamp((BB_BANDWIDTH_MAX_SOFT - bw_now)/max(BB_BANDWIDTH_MAX_SOFT,1e-9), 0, 1)
    
    # 2. Ù‚ÙˆØ© Ø§Ù„Ø§Ø®ØªØ±Ø§Ù‚
    breakout = clamp(((c_now - band_now) if side=="LONG" else (band_now - c_now))/max(atr_now,1e-9), 0, 1.5)
    breakout = min(breakout, 1.0)
    
    # 3. Ø²Ø®Ù… MACD
    mom = clamp(abs(macd_now - macd_sig)/max(atr_now,1e-9), 0, 1)
    
    # 4. RSI Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ
    rsi_target = 60 if side=="LONG" else 40
    rsi_score = clamp(1 - abs(r14 - rsi_target)/25.0, 0, 1)
    
    # 5. âœ¨ Stochastic - Ù‡Ù„ ÙÙŠ Ø²Ø®Ù…ØŸ
    if side == "LONG":
        stoch_score = clamp((stoch_k - 30) / 40.0, 0, 1)  # Ù†Ø¨ÙŠ ÙÙˆÙ‚ 30 Ù„Ù„Ø´Ø±Ø§Ø¡
    else:
        stoch_score = clamp((70 - stoch_k) / 40.0, 0, 1)  # Ù†Ø¨ÙŠ ØªØ­Øª 70 Ù„Ù„Ø¨ÙŠØ¹
    
    # 6. âœ¨ ADX - Ù‚ÙˆØ© Ø§Ù„ØªØ±Ù†Ø¯
    adx_score = clamp((adx_val - 20) / 30.0, 0, 1)  # Ø£ÙØ¶Ù„ Ù„Ùˆ ADX ÙÙˆÙ‚ 20
    
    # 7. âœ¨ Ø§ØªØ¬Ø§Ù‡ DI
    if side == "LONG":
        di_score = clamp((plus_di - minus_di) / 20.0, 0, 1)
    else:
        di_score = clamp((minus_di - plus_di) / 20.0, 0, 1)
    
    # 8. âœ¨ Ø§Ù„Ø­Ø¬Ù… - Ù‡Ù„ Ø§Ù„Ø³ÙˆÙ‚ Ù†Ø´Ø·ØŸ
    volume_score = clamp(volume_ratio - 0.8, 0, 1)  # Ù†Ø¨ÙŠ Ø­Ø¬Ù… ÙÙˆÙ‚ Ø§Ù„Ù…Ø¹Ø¯Ù„
    
    # Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø©
    confidence = int(round(100 * (
        0.18 * tight +          # Ø§Ù†Ø¶ØºØ§Ø·
        0.22 * breakout +       # Ø§Ø®ØªØ±Ø§Ù‚
        0.12 * mom +            # MACD
        0.12 * rsi_score +      # RSI
        0.12 * stoch_score +    # Stochastic Ø¬Ø¯ÙŠØ¯
        0.10 * adx_score +      # ADX Ø¬Ø¯ÙŠØ¯
        0.08 * di_score +       # DI Ø¬Ø¯ÙŠØ¯
        0.06 * volume_score     # Volume Ø¬Ø¯ÙŠØ¯
    )))
    
    return max(0, min(100, confidence))

def smart_signal_optimized(df: pd.DataFrame) -> Tuple[Optional[Dict], Dict]:
    """
    Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø© Ù…Ø¹ Ù…Ø¤Ø´Ø±Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
    """
    if df is None or len(df)<60: 
        return None, {"insufficient_data":True}

    c=df["close"]
    h=df["high"]
    l=df["low"]
    v=df["volume"]
    
    # Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    ma20, bb_up, bb_dn, bb_bw = bollinger(c, 20, 2.0)
    macd_line, macd_sig = macd(c, 12, 26, 9)
    r = rsi(c, 14)
    atr14 = atr(df, 14)
    ema50 = ema(c, 50)
    ema200 = ema(c, 200)
    
    # âœ¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
    stoch_k, stoch_d = stochastic(df, 14, 3)
    adx_val, plus_di, minus_di = adx(df, 14)
    
    # Ù†Ø³Ø¨Ø© Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù„Ù…ØªÙˆØ³Ø·
    avg_volume = v.tail(30).mean()
    current_volume = v.iloc[-2]
    volume_ratio = current_volume / max(avg_volume, 1e-9)

    i2, i1 = -3, -2
    try:
        c_prev = _f(c.iloc[i2])
        c_now = _f(c.iloc[i1])
        up_prev = _f(bb_up.iloc[i2])
        up_now = _f(bb_up.iloc[i1])
        dn_prev = _f(bb_dn.iloc[i2])
        dn_now = _f(bb_dn.iloc[i1])
        bw_now = _f(bb_bw.iloc[i1])
        macd_now = _f(macd_line.iloc[i1])
        sig_now = _f(macd_sig.iloc[i1])
        r14 = _f(r.iloc[i1])
        atr_now = _f(atr14.iloc[i1])
        e50 = _f(ema50.iloc[i1])
        e200 = _f(ema200.iloc[i1])
        ma20_prev = _f(ma20.iloc[i2])
        
        # âœ¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        stoch_k_now = _f(stoch_k.iloc[i1])
        stoch_d_now = _f(stoch_d.iloc[i1])
        adx_now = _f(adx_val.iloc[i1])
        plus_di_now = _f(plus_di.iloc[i1])
        minus_di_now = _f(minus_di.iloc[i1])
        
    except Exception:
        return None, {"index_or_nan": True}

    atr_pct = 100 * atr_now / max(c_now, 1e-9)
    
    try:
        avg_usdt = float((df["volume"] * c).tail(30).mean())
        if math.isnan(avg_usdt) or math.isinf(avg_usdt): 
            avg_usdt = 0.0
    except Exception:
        avg_usdt = 0.0

    # âœ¨ ÙÙ„ØªØ±Ø© Ø£Ù‚Ù„ ØµØ±Ø§Ù…Ø©
    if (atr_pct < MIN_ATR_PCT) or (avg_usdt < MIN_AVG_VOL_USDT):
        return None, {
            "atr_pct": round(atr_pct, 3), 
            "avg_vol_usdt": int(avg_usdt), 
            "note": "low_vol_or_range"
        }

    # Ø´Ø±ÙˆØ· Bollinger
    squeeze_strict = bw_now <= BB_BANDWIDTH_MAX
    squeeze_soft = bw_now <= BB_BANDWIDTH_MAX_SOFT
    squeeze_ok = bool(squeeze_strict or (ALLOW_NO_SQUEEZE and squeeze_soft))

    # Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„ØªØ±Ù†Ø¯
    trend_up = e50 > e200
    trend_down = e50 < e200
    trend_ok_long = (not REQUIRE_TREND) or trend_up
    trend_ok_short = (not REQUIRE_TREND) or trend_down

    # Ø§Ø®ØªØ±Ø§Ù‚Ø§Øª
    crossed_up = bool((c_prev <= up_prev) and (c_now > up_now))
    crossed_down = bool((c_prev >= dn_prev) and (c_now < dn_now))

    # âœ¨ Ø´Ø±ÙˆØ· Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø© - Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø©
    long_price_ok = bool(
        crossed_up or 
        ((c_now > up_now) and (c_prev > ma20_prev)) or
        (c_now > ma20_prev and c_now > e50)  # Ø´Ø±Ø· Ø¥Ø¶Ø§ÙÙŠ
    )
    
    short_price_ok = bool(
        crossed_down or 
        ((c_now < dn_now) and (c_prev < ma20_prev)) or
        (c_now < ma20_prev and c_now < e50)  # Ø´Ø±Ø· Ø¥Ø¶Ø§ÙÙŠ
    )

    # âœ¨ Ø²Ø®Ù… Ù…Ø­Ø³Ù‘Ù† Ù…Ø¹ Stochastic
    long_momentum = bool(
        (macd_now > sig_now) or 
        (c_now > e50) or
        (stoch_k_now > stoch_d_now and stoch_k_now > 25)  # Stochastic ØµØ§Ø¹Ø¯
    )
    
    short_momentum = bool(
        (macd_now < sig_now) or 
        (c_now < e50) or
        (stoch_k_now < stoch_d_now and stoch_k_now < 75)  # Stochastic Ù†Ø§Ø²Ù„
    )

    # RSI
    rsi_long_ok = bool(RSI_LONG_MIN < r14 < RSI_LONG_MAX)
    rsi_short_ok = bool(RSI_SHORT_MIN < r14 < RSI_SHORT_MAX)
    
    # âœ¨ ADX - Ù†ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø³ÙˆÙ‚ ÙÙŠÙ‡ Ù‚ÙˆØ©
    adx_ok = adx_now > 18  # ADX ÙÙˆÙ‚ 18 ÙŠØ¹Ù†ÙŠ ÙÙŠÙ‡ Ù‚ÙˆØ© Ø­Ø±ÙƒØ©

    # âœ¨ Ø§Ù„Ø´Ø±ÙˆØ· Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø©
    long_ok = bool(
        squeeze_ok and 
        long_price_ok and 
        long_momentum and 
        rsi_long_ok and 
        trend_ok_long and
        (adx_ok or volume_ratio > 1.2)  # Ø¥Ù…Ø§ ADX Ù‚ÙˆÙŠ Ø£Ùˆ Ø­Ø¬Ù… Ø¹Ø§Ù„ÙŠ
    )
    
    short_ok = bool(
        squeeze_ok and 
        short_price_ok and 
        short_momentum and 
        rsi_short_ok and 
        trend_ok_short and
        (adx_ok or volume_ratio > 1.2)
    )

    if not (long_ok or short_ok):
        return None, {
            "squeeze": squeeze_ok,
            "bw_now": round(bw_now, 5),
            "rsi14": round(r14, 2),
            "stoch_k": round(stoch_k_now, 2),
            "adx": round(adx_now, 2),
            "volume_ratio": round(volume_ratio, 2),
            "cross_up": crossed_up,
            "cross_down": crossed_down,
            "macd_vs_signal": f"{round(macd_now,4)} vs {round(sig_now,4)}",
            "trend": "up" if trend_up else ("down" if trend_down else "flat"),
        }

    side = "LONG" if long_ok else "SHORT"
    band_now = up_now if side == "LONG" else dn_now
    
    # âœ¨ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†
    conf = compute_confidence_advanced(
        side, bw_now, c_prev, c_now, band_now, 
        macd_now, sig_now, r14, atr_now,
        stoch_k_now, stoch_d_now, adx_now,
        plus_di_now, minus_di_now, volume_ratio
    )

    # âœ¨ Ø³ØªÙˆØ¨ Ù„ÙˆØ³ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø£Ø°ÙƒÙ‰
    recent_lows = float(l.tail(SL_LOOKBACK).min())
    recent_highs = float(h.tail(SL_LOOKBACK).max())
    entry = c_now
    atr_dist = ATR_SL_MULT * max(atr_now, 1e-12)
    
    if side == "LONG":
        # Ø³ØªÙˆØ¨ Ù„ÙˆØ³ Ù„Ù„Ø´Ø±Ø§Ø¡
        sl_atr = entry - atr_dist
        sl_swing = recent_lows - (0.1 * atr_now)  # ØªØ­Øª Ø§Ù„Ø³ÙˆÙŠÙ†Øº Ø¨Ù‚Ù„ÙŠÙ„
        sl_raw = max(sl_atr, sl_swing)  # Ù†Ø®ØªØ§Ø± Ø§Ù„Ø£Ø¨Ø¹Ø¯ Ù„Ù„Ø£Ù…Ø§Ù†
        
        min_gap = entry * (MIN_SL_PCT / 100.0)
        max_gap = entry * (MAX_SL_PCT / 100.0)
        gap = entry - sl_raw
        
        if gap < min_gap: 
            sl_raw = entry - min_gap
        if gap > max_gap: 
            sl_raw = entry - max_gap
    else:
        # Ø³ØªÙˆØ¨ Ù„ÙˆØ³ Ù„Ù„Ø¨ÙŠØ¹
        sl_atr = entry + atr_dist
        sl_swing = recent_highs + (0.1 * atr_now)  # ÙÙˆÙ‚ Ø§Ù„Ø³ÙˆÙŠÙ†Øº Ø¨Ù‚Ù„ÙŠÙ„
        sl_raw = min(sl_atr, sl_swing)  # Ù†Ø®ØªØ§Ø± Ø§Ù„Ø£Ø¨Ø¹Ø¯ Ù„Ù„Ø£Ù…Ø§Ù†
        
        min_gap = entry * (MIN_SL_PCT / 100.0)
        max_gap = entry * (MAX_SL_PCT / 100.0)
        gap = sl_raw - entry
        
        if gap < min_gap: 
            sl_raw = entry + min_gap
        if gap > max_gap: 
            sl_raw = entry + max_gap
    
    sl = float(sl_raw)
    
    # âœ¨ Ø£Ù‡Ø¯Ø§Ù Ù…Ø­Ø³Ù‘Ù†Ø©
    if side == "LONG":
        tps = [entry * (1 + p/100.0) for p in TP_PCTS]
    else:
        tps = [entry * (1 - p/100.0) for p in TP_PCTS]
    
    return (
        {
            "side": side,
            "entry": float(entry),
            "sl": sl,
            "tps": [float(x) for x in tps],
            "confidence": int(conf),
            "adx": round(adx_now, 2),
            "volume_ratio": round(volume_ratio, 2),
            "stoch": round(stoch_k_now, 2)
        }, 
        {}
    )

# ================== TP/SL ==================
def crossed_levels(side:str, price:float, tps:List[float], sl:float, hit:List[bool]):
    if price is None: 
        return None
    
    if side == "LONG" and price <= sl: 
        return ("SL", -1)
    if side == "SHORT" and price >= sl: 
        return ("SL", -1)
    
    for idx, (tp, was_hit) in enumerate(zip(tps, hit)):
        if was_hit: 
            continue
        if side == "LONG" and price >= tp: 
            return ("TP", idx)
        if side == "SHORT" and price <= tp: 
            return ("TP", idx)
    
    return None

def pct_profit(side:str, entry:float, exit_price:float)->float:
    if side == "LONG":
        return (exit_price / entry - 1.0) * 100.0
    else:
        return (1.0 - exit_price / entry) * 100.0

def elapsed_text(start_ts:int, end_ts:int)->str:
    mins = max(0, end_ts - start_ts) // 60
    if mins < 60:
        return f"{mins} Ø¯Ù‚ÙŠÙ‚Ø©"
    else:
        return f"{mins//60} Ø³Ø§Ø¹Ø© {mins%60} Ø¯Ù‚ÙŠÙ‚Ø©"

# ================== FastAPI ==================
app = FastAPI()

@app.get("/")
def root():
    return {
        "ok": True,
        "version": APP_VERSION,
        "exchange": getattr(app.state, "exchange_id", EXCHANGE_NAME),
        "tf": TIMEFRAME,
        "symbols": len(getattr(app.state, "symbols", [])),
        "open_trades": len(open_trades)
    }

@app.get("/stats")
def stats():
    """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø© Ø¹Ø¨Ø± API"""
    return {
        "open_trades": len(open_trades),
        "cycle_count": getattr(app.state, "cycle_count", 0),
        "symbols_count": len(getattr(app.state, "symbols", [])),
        "exchange": getattr(app.state, "exchange_id", ""),
    }

# ================== Scan & Trade ==================
async def fetch_and_signal(ex, symbol:str):
    global _last_cycle_alerts
    
    out = await fetch_ohlcv_safe(ex, symbol, TIMEFRAME, 300)
    
    if isinstance(out, str): 
        db_insert_error(unix_now(), ex.id, symbol, out)
        return
    
    if out is None or len(out) < 60: 
        db_insert_nosignal(unix_now(), ex.id, symbol, {"insufficient_data": True})
        return

    st = signal_state.get(symbol, {})
    closed_idx = len(out) - 2
    
    if closed_idx < st.get("cooldown_until_idx", -999999): 
        return
    
    if symbol in open_trades: 
        return

    try:
        sig, reasons = smart_signal_optimized(out)
    except Exception as e:
        _error_bucket.append(f"{symbol}: {type(e).__name__} {str(e)}")
        return

    if not sig:
        db_insert_nosignal(unix_now(), ex.id, symbol, reasons or {"note": "no_setup"})
        return
    
    if sig["confidence"] < MIN_CONFIDENCE:
        db_insert_nosignal(unix_now(), ex.id, symbol, {
            **reasons, 
            "confidence_lt_min": sig["confidence"]
        })
        return
    
    if _last_cycle_alerts >= MAX_ALERTS_PER_CYCLE:
        db_insert_nosignal(unix_now(), ex.id, symbol, {"cycle_cap_reached": True})
        return

    # âœ¨ Ø±Ø³Ø§Ù„Ø© Ù…Ø­Ø³Ù‘Ù†Ø© Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£ÙƒØ«Ø±
    pretty = symbol_pretty(symbol)
    side_txt = "Ø·ÙˆÙŠÙ„ ğŸŸ¢" if sig["side"] == "LONG" else "Ù‚ØµÙŠØ± ğŸ”´"
    entry, sl, tps, conf = sig["entry"], sig["sl"], sig["tps"], sig["confidence"]
    
    # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©/Ø§Ù„Ø±Ø¨Ø­
    risk = abs(entry - sl)
    reward = abs(tps[2] - entry)  # Ù†Ø³ØªØ®Ø¯Ù… TP3 ÙƒÙ‡Ø¯Ù Ø±Ø¦ÙŠØ³ÙŠ
    rr_ratio = reward / risk if risk > 0 else 0
    
    msg_text = (
        f"ğŸ¯ Ø¥Ø´Ø§Ø±Ø© Ø¬Ø¯ÙŠØ¯Ø© - #{pretty}\n"
        f"{'â”' * 30}\n\n"
        f"Ø§Ù„Ø§ØªØ¬Ø§Ù‡: {side_txt}\n"
        f"Ø§Ù„Ø«Ù‚Ø©: {conf}% {'ğŸ”¥' if conf >= 65 else 'â­' if conf >= 55 else 'ğŸ’«'}\n\n"
        f"ğŸ“ Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„: {entry:.6f}\n"
        f"ğŸ›‘ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©: {sl:.6f}\n\n"
        f"ğŸ¯ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù:\n"
        f"  TP1: {tps[0]:.6f} ({TP_PCTS[0]}%)\n"
        f"  TP2: {tps[1]:.6f} ({TP_PCTS[1]}%)\n"
        f"  TP3: {tps[2]:.6f} ({TP_PCTS[2]}%) â­\n"
        f"  TP4: {tps[3]:.6f} ({TP_PCTS[3]}%)\n\n"
        f"ğŸ“Š Ù†Ø³Ø¨Ø© R/R: 1:{rr_ratio:.2f}\n"
        f"ğŸ“ˆ ADX: {sig.get('adx', 0):.1f} | Vol: {sig.get('volume_ratio', 1):.1f}x\n"
        f"{'â”' * 30}"
    )
    
    mid = send_telegram(msg_text)
    
    if mid:
        ts_now = unix_now()
        open_trades[symbol] = {
            "side": sig["side"],
            "entry": entry,
            "sl": sl,
            "tps": tps,
            "hit": [False] * 4,
            "msg_id": mid,
            "signal_id": None,
            "opened_ts": ts_now
        }
        
        signal_state[symbol] = {
            "cooldown_until_idx": closed_idx + COOLDOWN_PER_SYMBOL_CANDLES
        }
        
        sid = db_insert_signal(
            ts_now, app.state.exchange.id, symbol, 
            sig["side"], entry, sl, tps, conf, mid
        )
        
        open_trades[symbol]["signal_id"] = sid
        _last_cycle_alerts += 1

async def check_open_trades(ex):
    """ÙØ­Øµ Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© ÙˆØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„ØªÙ‡Ø§"""
    for sym, pos in list(open_trades.items()):
        price = await fetch_ticker_price(ex, sym)
        res = crossed_levels(pos["side"], price, pos["tps"], pos["sl"], pos["hit"])
        
        if not res: 
            continue
        
        kind, idx = res
        ts = unix_now()
        
        if kind == "SL":
            pr = pct_profit(pos["side"], pos["entry"], price or pos["sl"])
            
            msg = (
                f"âŒ #{symbol_pretty(sym)}\n"
                f"{'â”' * 25}\n"
                f"ØªÙ… Ø¶Ø±Ø¨ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©\n\n"
                f"ğŸ“‰ Ø§Ù„Ø®Ø³Ø§Ø±Ø©: {round(pr, 2)}%\n"
                f"â° Ø§Ù„Ù…Ø¯Ø©: {elapsed_text(pos['opened_ts'], ts)}\n"
                f"ğŸ’¡ Ø§Ù„Ø³Ø¹Ø±: {price or pos['sl']:.6f}"
            )
            
            send_telegram(msg)
            
            if pos.get("signal_id"): 
                db_insert_outcome(pos["signal_id"], ts, "SL", -1, price or 0.0)
            
            del open_trades[sym]
            
        else:
            pos["hit"][idx] = True
            tp = pos["tps"][idx]
            pr = pct_profit(pos["side"], pos["entry"], tp if price is None else price)
            
            # Ø±Ù…ÙˆØ² Ù…Ø®ØªÙ„ÙØ© Ø­Ø³Ø¨ Ø§Ù„Ù‡Ø¯Ù
            emoji_map = ["ğŸ¯", "â­", "ğŸ”¥", "ğŸ’"]
            emoji = emoji_map[idx] if idx < len(emoji_map) else "âœ…"
            
            msg = (
                f"{emoji} #{symbol_pretty(sym)}\n"
                f"{'â”' * 25}\n"
                f"ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù‡Ø¯Ù {idx+1}\n\n"
                f"ğŸ“ˆ Ø§Ù„Ø±Ø¨Ø­: +{round(pr, 2)}%\n"
                f"â° Ø§Ù„Ù…Ø¯Ø©: {elapsed_text(pos['opened_ts'], ts)}\n"
                f"ğŸ’° Ø§Ù„Ø³Ø¹Ø±: {price or tp:.6f}"
            )
            
            send_telegram(msg)
            
            if pos.get("signal_id"): 
                db_insert_outcome(pos["signal_id"], ts, f"TP{idx+1}", idx, price or tp)
            
            # Ø¥Ø°Ø§ ÙƒÙ„ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø§ØªØ­Ù‚Ù‚ØªØŒ Ù†ØºÙ„Ù‚ Ø§Ù„ØµÙÙ‚Ø©
            if all(pos["hit"]): 
                total_profit = sum([
                    pct_profit(pos["side"], pos["entry"], pos["tps"][i]) 
                    for i in range(4)
                ]) / 4
                
                final_msg = (
                    f"ğŸ‰ #{symbol_pretty(sym)}\n"
                    f"{'â”' * 25}\n"
                    f"ØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ØµÙÙ‚Ø© Ø¨Ù†Ø¬Ø§Ø­!\n\n"
                    f"ğŸ“Š Ù…ØªÙˆØ³Ø· Ø§Ù„Ø±Ø¨Ø­: +{round(total_profit, 2)}%\n"
                    f"â° Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¯Ø©: {elapsed_text(pos['opened_ts'], ts)}"
                )
                
                send_telegram(final_msg)
                del open_trades[sym]

async def scan_once(ex, symbols:List[str]):
    """Ø¯ÙˆØ±Ø© Ù…Ø³Ø­ ÙˆØ§Ø­Ø¯Ø©"""
    global _last_cycle_alerts, _error_last_flush, _error_bucket
    
    _last_cycle_alerts = 0
    
    # ÙØ­Øµ Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© Ø£ÙˆÙ„Ø§Ù‹
    await check_open_trades(ex)
    
    if not symbols: 
        return
    
    # Ø®Ù„Ø· Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ù„Ù„Ø±Ù…ÙˆØ² Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ­Øµ
    random.shuffle(symbols)
    
    # Ø³ÙŠÙ…Ø§ÙÙˆØ± Ù„Ù„ØªØ­ÙƒÙ… Ø¨Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©
    sem = asyncio.Semaphore(5)  # Ø²Ø¯Ù†Ø§ Ù…Ù† 3 Ø¥Ù„Ù‰ 5
    
    async def worker(s):
        async with sem: 
            await fetch_and_signal(ex, s)
    
    await asyncio.gather(*[asyncio.create_task(worker(s)) for s in symbols])

    # flush errors Ø¨Ø´ÙƒÙ„ Ø¯ÙˆØ±ÙŠ
    now = time.time()
    if _error_bucket and (now - _error_last_flush >= ERROR_FLUSH_EVERY):
        sample = "\n".join(_error_bucket[:8])
        send_telegram(f"âš ï¸ Ù…Ù„Ø®Øµ Ø£Ø®Ø·Ø§Ø¡ ({len(_error_bucket)}):\n{sample}")
        _error_bucket.clear()
        _error_last_flush = now

# ================== ØªÙ‚Ø§Ø±ÙŠØ±/Ø£ÙˆØ§Ù…Ø± Ù…Ø­Ø³Ù‘Ù†Ø© ==================
def db_text_stats(days:int=1)->str:
    """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø£Ø³Ø§Ø³ÙŠØ© Ø³Ø±ÙŠØ¹Ø©"""
    try:
        con = db_conn()
        cur = con.cursor()
        
        cur.execute(
            "SELECT COUNT(*) FROM signals WHERE ts >= strftime('%s','now', ?)", 
            (f"-{days} day",)
        )
        total = cur.fetchone()[0] or 0
        
        cur.execute("""
            SELECT SUM(CASE WHEN event LIKE 'TP%' THEN 1 ELSE 0 END),
                   SUM(CASE WHEN event='SL' THEN 1 ELSE 0 END)
            FROM outcomes WHERE ts >= strftime('%s','now', ?)
        """, (f"-{days} day",))
        
        row = cur.fetchone() or (0, 0)
        tp, sl = row[0] or 0, row[1] or 0
        
        # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­
        if total > 0:
            success_rate = (tp / (tp + sl) * 100) if (tp + sl) > 0 else 0
        else:
            success_rate = 0
        
        con.close()
        
        if total == 0 and tp == 0 and sl == 0: 
            return "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ø¨Ø¹Ø¯."
        
        return (
            f"ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¢Ø®Ø± {days} ÙŠÙˆÙ…:\n"
            f"{'â”' * 25}\n"
            f"ğŸ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª: {total}\n"
            f"âœ… Ø£Ù‡Ø¯Ø§Ù Ù…Ø­Ù‚Ù‚Ø©: {tp}\n"
            f"âŒ Ø³ØªÙˆØ¨ Ù„ÙˆØ³: {sl}\n"
            f"ğŸ“ˆ Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­: {success_rate:.1f}%\n"
            f"{'â”' * 25}"
        )
    except Exception as e:
        return f"âš ï¸ Ø®Ø·Ø£ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: {e}"

def db_detailed_stats(days:int=7)->str:
    """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ØªÙØµÙŠÙ„ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„ØªØ·ÙˆÙŠØ±"""
    try:
        con = db_conn()
        cur = con.cursor()
        
        # 1. Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
        cur.execute("""
            SELECT COUNT(*), 
                   AVG(confidence),
                   COUNT(DISTINCT symbol)
            FROM signals 
            WHERE ts >= strftime('%s','now', ?)
        """, (f"-{days} day",))
        
        total_signals, avg_conf, unique_symbols = cur.fetchone()
        total_signals = total_signals or 0
        avg_conf = avg_conf or 0
        unique_symbols = unique_symbols or 0
        
        # 2. ØªÙØ§ØµÙŠÙ„ LONG vs SHORT
        cur.execute("""
            SELECT side, COUNT(*), AVG(confidence)
            FROM signals 
            WHERE ts >= strftime('%s','now', ?)
            GROUP BY side
        """, (f"-{days} day",))
        
        side_stats = {}
        for row in cur.fetchall():
            side_stats[row[0]] = {"count": row[1], "avg_conf": row[2] or 0}
        
        # 3. Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ TP/SL
        cur.execute("""
            SELECT o.event, COUNT(*), AVG(s.confidence)
            FROM outcomes o
            JOIN signals s ON o.signal_id = s.id
            WHERE o.ts >= strftime('%s','now', ?)
            GROUP BY o.event
        """, (f"-{days} day",))
        
        outcome_stats = {}
        for row in cur.fetchall():
            outcome_stats[row[0]] = {"count": row[1], "avg_conf": row[2] or 0}
        
        # 4. Ø£ÙØ¶Ù„ ÙˆØ£Ø³ÙˆØ£ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬
        cur.execute("""
            SELECT s.symbol,
                   COUNT(*) as total,
                   SUM(CASE WHEN o.event LIKE 'TP%' THEN 1 ELSE 0 END) as wins,
                   SUM(CASE WHEN o.event = 'SL' THEN 1 ELSE 0 END) as losses
            FROM signals s
            LEFT JOIN outcomes o ON s.id = o.signal_id
            WHERE s.ts >= strftime('%s','now', ?)
            GROUP BY s.symbol
            HAVING total >= 2
            ORDER BY (CAST(wins AS FLOAT) / NULLIF(wins + losses, 0)) DESC
            LIMIT 5
        """, (f"-{days} day",))
        
        best_pairs = cur.fetchall()
        
        # 5. ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø«Ù‚Ø©
        cur.execute("""
            SELECT 
                CASE 
                    WHEN confidence < 50 THEN '40-50'
                    WHEN confidence < 55 THEN '50-55'
                    WHEN confidence < 60 THEN '55-60'
                    WHEN confidence < 65 THEN '60-65'
                    WHEN confidence < 70 THEN '65-70'
                    ELSE '70+'
                END as conf_range,
                COUNT(*) as count,
                SUM(CASE WHEN o.event LIKE 'TP%' THEN 1 ELSE 0 END) as wins,
                SUM(CASE WHEN o.event = 'SL' THEN 1 ELSE 0 END) as losses
            FROM signals s
            LEFT JOIN outcomes o ON s.id = o.signal_id
            WHERE s.ts >= strftime('%s','now', ?)
            GROUP BY conf_range
            ORDER BY conf_range
        """, (f"-{days} day",))
        
        conf_distribution = cur.fetchall()
        
        # 6. Ù…ØªÙˆØ³Ø· ÙˆÙ‚Øª Ø§Ù„ØµÙÙ‚Ø§Øª
        cur.execute("""
            SELECT AVG(o.ts - s.ts) / 60.0 as avg_minutes
            FROM signals s
            JOIN outcomes o ON s.id = o.signal_id
            WHERE s.ts >= strftime('%s','now', ?)
        """, (f"-{days} day",))
        
        avg_duration = cur.fetchone()[0] or 0
        
        # 7. Ø£Ø³Ø¨Ø§Ø¨ Ø¹Ø¯Ù… Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª (Ø£Ù‡Ù… 5)
        cur.execute("""
            SELECT reasons
            FROM nosignal_reasons
            WHERE ts >= strftime('%s','now', ?)
        """, (f"-{days} day",))
        
        from collections import Counter
        reason_counter = Counter()
        for (js,) in cur.fetchall():
            try:
                d = json.loads(js) if isinstance(js, str) else {}
                if isinstance(d, dict):
                    for k in d.keys():
                        reason_counter[k] += 1
            except:
                pass
        
        top_reasons = reason_counter.most_common(5)
        
        con.close()
        
        # Ø¨Ù†Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        if total_signals == 0:
            return "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ."
        
        output = [
            f"ğŸ“Š ØªÙ‚Ø±ÙŠØ± ØªØ­Ù„ÙŠÙ„ÙŠ Ù…ØªÙ‚Ø¯Ù… ({days} ÙŠÙˆÙ…)",
            "â•" * 40,
            "",
            "â–¶ï¸ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©:",
            f"  â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª: {total_signals}",
            f"  â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©: {avg_conf:.1f}%",
            f"  â€¢ Ø£Ø²ÙˆØ§Ø¬ Ù…Ø®ØªÙ„ÙØ©: {unique_symbols}",
            f"  â€¢ Ù…ØªÙˆØ³Ø· Ù…Ø¯Ø© Ø§Ù„ØµÙÙ‚Ø©: {avg_duration:.0f} Ø¯Ù‚ÙŠÙ‚Ø©",
            "",
            "â–¶ï¸ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª:"
        ]
        
        for side, data in side_stats.items():
            output.append(f"  â€¢ {side}: {data['count']} Ø¥Ø´Ø§Ø±Ø© (Ø«Ù‚Ø©: {data['avg_conf']:.1f}%)")
        
        output.append("")
        output.append("â–¶ï¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹:")
        
        total_tp = sum(v["count"] for k, v in outcome_stats.items() if k.startswith("TP"))
        total_sl = outcome_stats.get("SL", {}).get("count", 0)
        
        if total_tp + total_sl > 0:
            win_rate = (total_tp / (total_tp + total_sl)) * 100
            output.append(f"  â€¢ Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ Ø§Ù„ÙƒÙ„ÙŠØ©: {win_rate:.1f}%")
        
        for event, data in sorted(outcome_stats.items()):
            output.append(f"  â€¢ {event}: {data['count']} (Ø«Ù‚Ø© Ù…ØªÙˆØ³Ø·Ø©: {data['avg_conf']:.1f}%)")
        
        output.append("")
        output.append("â–¶ï¸ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø«Ù‚Ø© vs Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
        
        for conf_range, count, wins, losses in conf_distribution:
            wins = wins or 0
            losses = losses or 0
            if wins + losses > 0:
                wr = (wins / (wins + losses)) * 100
                output.append(f"  â€¢ {conf_range}%: {count} Ø¥Ø´Ø§Ø±Ø§Øª â†’ WR: {wr:.1f}%")
            else:
                output.append(f"  â€¢ {conf_range}%: {count} Ø¥Ø´Ø§Ø±Ø§Øª â†’ Ù‚ÙŠØ¯ Ø§Ù„ØªÙ†ÙÙŠØ°")
        
        if best_pairs:
            output.append("")
            output.append("â–¶ï¸ Ø£ÙØ¶Ù„ 5 Ø£Ø²ÙˆØ§Ø¬:")
            for symbol, total, wins, losses in best_pairs:
                wins = wins or 0
                losses = losses or 0
                if wins + losses > 0:
                    wr = (wins / (wins + losses)) * 100
                    output.append(f"  â€¢ {symbol_pretty(symbol)}: {wins}W/{losses}L ({wr:.0f}%)")
        
        if top_reasons:
            output.append("")
            output.append("â–¶ï¸ Ø£Ù‡Ù… Ø£Ø³Ø¨Ø§Ø¨ Ø¹Ø¯Ù… Ø§Ù„Ø¥Ø´Ø§Ø±Ø©:")
            for reason, count in top_reasons:
                output.append(f"  â€¢ {reason}: {count}")
        
        output.append("")
        output.append("â•" * 40)
        output.append("ğŸ’¡ Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ù‡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø¶Ø¨Ø· Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
        
        return "\n".join(output)
        
    except Exception as e:
        return f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ: {e}\n{traceback.format_exc()}"

def db_export_analysis_csv(days:int=14)->bytes:
    """ØªØµØ¯ÙŠØ± CSV Ù…ØªÙ‚Ø¯Ù… Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ"""
    con = db_conn()
    cur = con.cursor()
    
    # Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø´Ø§Ù…Ù„ ÙŠØ¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©
    cur.execute("""
        SELECT 
            s.id,
            datetime(s.ts, 'unixepoch') as signal_time,
            s.exchange,
            s.symbol,
            s.side,
            s.entry,
            s.sl,
            s.tp1, s.tp2, s.tp3, s.tp4,
            s.confidence,
            (s.entry - s.sl) / s.entry * 100 as risk_pct,
            (SELECT event FROM outcomes o WHERE o.signal_id = s.id ORDER BY o.ts LIMIT 1) as first_outcome,
            (SELECT price FROM outcomes o WHERE o.signal_id = s.id ORDER BY o.ts LIMIT 1) as outcome_price,
            (SELECT (o.ts - s.ts) / 60.0 FROM outcomes o WHERE o.signal_id = s.id ORDER BY o.ts LIMIT 1) as duration_minutes,
            (SELECT COUNT(*) FROM outcomes o WHERE o.signal_id = s.id AND o.event LIKE 'TP%') as tp_hits,
            CASE 
                WHEN EXISTS(SELECT 1 FROM outcomes o WHERE o.signal_id = s.id AND o.event = 'SL') THEN 'LOSS'
                WHEN EXISTS(SELECT 1 FROM outcomes o WHERE o.signal_id = s.id AND o.event LIKE 'TP%') THEN 'WIN'
                ELSE 'OPEN'
            END as status,
            (SELECT GROUP_CONCAT(event || '@' || price, '|') FROM outcomes o WHERE o.signal_id = s.id) as all_outcomes
        FROM signals s
        WHERE s.ts >= strftime('%s', 'now', ?)
        ORDER BY s.ts DESC
    """, (f"-{days} day",))
    
    rows = cur.fetchall()
    con.close()
    
    out = io.StringIO()
    w = csv.writer(out)
    
    # Headers
    w.writerow([
        "ID", "Signal_Time", "Exchange", "Symbol", "Side", 
        "Entry", "SL", "TP1", "TP2", "TP3", "TP4", 
        "Confidence", "Risk_%", "First_Outcome", "Outcome_Price", 
        "Duration_Minutes", "TP_Hits", "Status", "All_Outcomes"
    ])
    
    for r in rows:
        w.writerow(r)
    
    return out.getvalue().encode("utf-8")

def db_text_reasons(window:str="1d")->str:
    unit = window[-1].lower()
    num = int(''.join([ch for ch in window if ch.isdigit()]) or 1)
    sql_win = f"-{num} {'hour' if unit=='h' else 'day'}"
    
    try:
        con = db_conn()
        cur = con.cursor()
        cur.execute(
            "SELECT reasons FROM nosignal_reasons WHERE ts >= strftime('%s','now', ?)", 
            (sql_win,)
        )
        rows = cur.fetchall()
        con.close()
        
        if not rows: 
            return "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø³Ø¨Ø§Ø¨ Ù…Ø³Ø¬Ù„Ø© ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¯Ø©."
        
        from collections import Counter
        cnt = Counter()
        
        for (js,) in rows:
            try:
                d = json.loads(js) if isinstance(js, str) else {}
                if isinstance(d, dict):
                    for k in d.keys(): 
                        cnt[k] += 1
                else: 
                    cnt["other"] += 1
            except: 
                cnt["other"] += 1
        
        lines = [f"ğŸ“„ Ø£Ù‡Ù… Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ ({window}):"]
        lines.append("â”" * 25)
        lines.extend([f"{i+1}. {k}: {v}" for i, (k, v) in enumerate(cnt.most_common(10))])
        
        return "\n".join(lines)
    except Exception as e:
        return f"âš ï¸ Ø®Ø·Ø£ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨: {e}"

def db_text_last(limit:int=10)->str:
    try:
        con = db_conn()
        cur = con.cursor()
        cur.execute("""
            SELECT s.id, datetime(s.ts,'unixepoch'), s.symbol, s.side, s.entry, s.sl, s.confidence,
                   (SELECT event FROM outcomes o WHERE o.signal_id=s.id ORDER BY o.ts LIMIT 1)
            FROM signals s ORDER BY s.id DESC LIMIT ?
        """, (limit,))
        rows = cur.fetchall()
        con.close()
        
        if not rows: 
            return "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø´Ø§Ø±Ø§Øª Ù…Ø³Ø¬Ù„Ø© Ø¨Ø¹Ø¯."
        
        out = ["ğŸ“œ Ø¢Ø®Ø± Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª:"]
        out.append("â”" * 30)
        
        for r in rows:
            result = r[7] or "Ù‚ÙŠØ¯ Ø§Ù„ØªÙ†ÙÙŠØ°..."
            emoji = "âœ…" if result and result.startswith("TP") else ("âŒ" if result == "SL" else "â³")
            out.append(f"{emoji} #{symbol_pretty(r[2])} {r[3]} | Ø«Ù‚Ø©:{r[6]}% â†’ {result}")
        
        return "\n".join(out)
    except Exception as e:
        return f"âš ï¸ Ø®Ø·Ø£ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø³Ø¬Ù„: {e}"

def db_text_open()->str:
    if not open_trades: 
        return "Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙÙ‚Ø§Øª Ù…ÙØªÙˆØ­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹."
    
    out = ["ğŸ“Œ Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©:"]
    out.append("â”" * 30)
    
    for s, p in open_trades.items():
        hit_count = sum(p["hit"])
        out.append(
            f"#{symbol_pretty(s)} {p['side']}\n"
            f"  Ø¯Ø®ÙˆÙ„: {p['entry']:.6f} | SL: {p['sl']:.6f}\n"
            f"  Ø£Ù‡Ø¯Ø§Ù Ù…Ø­Ù‚Ù‚Ø©: {hit_count}/4"
        )
    
    return "\n".join(out)

def export_csv_bytes(days:int=14)->bytes:
    con = db_conn()
    cur = con.cursor()
    cur.execute("""
        SELECT s.id, s.ts, s.exchange, s.symbol, s.side, s.entry, s.sl, 
               s.tp1, s.tp2, s.tp3, s.tp4, s.confidence,
               (SELECT GROUP_CONCAT(event||':'||price,'|') FROM outcomes o WHERE o.signal_id=s.id)
        FROM signals s WHERE s.ts >= strftime('%s','now', ?) ORDER BY s.id DESC
    """, (f"-{days} day",))
    rows = cur.fetchall()
    con.close()
    
    out = io.StringIO()
    w = csv.writer(out)
    w.writerow([
        "id", "ts", "exchange", "symbol", "side", "entry", "sl", 
        "tp1", "tp2", "tp3", "tp4", "confidence", "outcomes"
    ])
    
    for r in rows: 
        w.writerow(r)
    
    return out.getvalue().encode("utf-8")

# ================== Telegram Polling ==================
TG_OFFSET = 0

def tg_delete_webhook():
    try: 
        requests.post(TG_DELETE_WEBHOOK, data={"drop_pending_updates": False}, timeout=10)
    except Exception as e: 
        print("deleteWebhook error:", e)

def parse_cmd(text:str)->Tuple[str,str]:
    t = (text or "").strip()
    if t.startswith("/"):
        parts = t.split(maxsplit=1)
        cmd = parts[0].lower()
        arg = parts[1].strip() if len(parts) > 1 else ""
        if "@" in cmd: 
            cmd = cmd.split("@", 1)[0]
        return cmd, arg
    return t, ""

async def poll_telegram_commands():
    if not POLL_COMMANDS: 
        return
    
    tg_delete_webhook()
    global TG_OFFSET
    
    while True:
        try:
            r = requests.get(
                TG_GET_UPDATES, 
                params={"timeout": 25, "offset": TG_OFFSET + 1}, 
                timeout=35
            ).json()
            
            if r.get("ok"):
                for upd in r.get("result", []):
                    TG_OFFSET = max(TG_OFFSET, upd["update_id"])
                    msg = upd.get("message") or upd.get("edited_message")
                    
                    if not msg or str(msg.get("chat", {}).get("id")) != str(CHAT_ID): 
                        continue
                    
                    text = msg.get("text", "")
                    cmd, arg = parse_cmd(text)

                    if cmd in ("/start", "ğŸ” ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©"): 
                        send_start_menu()
                    
                    elif cmd in ("ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª", "/stats"):
                        days = int(arg) if arg.isdigit() else 1
                        send_telegram(db_text_stats(days))
                    
                    elif cmd in ("ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…", "/analysis", "/detailed"):
                        days = int(arg) if arg.isdigit() else 7
                        send_telegram(db_detailed_stats(days))
                    
                    elif cmd in ("ğŸ“„ Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨", "/reasons", "/reason"):
                        win = arg or "1d"
                        send_telegram(db_text_reasons(win))
                    
                    elif cmd in ("ğŸ“œ Ø¢Ø®Ø± Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª", "/last"):
                        lim = int(arg) if arg.isdigit() else 10
                        send_telegram(db_text_last(lim))
                    
                    elif cmd in ("ğŸ“Œ Ø§Ù„Ù…ÙØªÙˆØ­Ø©", "/open"): 
                        send_telegram(db_text_open())
                    
                    elif cmd in ("â¬‡ï¸ ØªØµØ¯ÙŠØ± CSV", "/export"):
                        days = int(arg) if arg.isdigit() else 14
                        send_document(
                            f"signals_{days}d.csv", 
                            export_csv_bytes(days), 
                            caption=f"ØªØµØ¯ÙŠØ± Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª ({days} ÙŠÙˆÙ…)"
                        )
                    
                    elif cmd in ("ğŸ“‹ ØªØµØ¯ÙŠØ± ØªØ­Ù„ÙŠÙ„ÙŠ", "/export_analysis", "/analysis_csv"):
                        days = int(arg) if arg.isdigit() else 14
                        send_document(
                            f"analysis_{days}d.csv",
                            db_export_analysis_csv(days),
                            caption=f"ØªØµØ¯ÙŠØ± ØªØ­Ù„ÙŠÙ„ÙŠ Ø´Ø§Ù…Ù„ ({days} ÙŠÙˆÙ…)\nÙ„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Excel/Python"
                        )
                    
                    elif cmd in ("/version", "Ù†Ø³Ø®Ø©", "Ø¥ØµØ¯Ø§Ø±"):
                        send_telegram(f"ğŸ¤– Ø§Ù„Ø¥ØµØ¯Ø§Ø±: v{APP_VERSION}")
                    
                    else:
                        send_start_menu()
        
        except Exception as e:
            print("poll error:", e)
        
        await asyncio.sleep(POLL_INTERVAL)

# ================== Keepalive ==================
async def keepalive_task():
    if not KEEPALIVE_URL: 
        return
    
    while True:
        try: 
            requests.get(KEEPALIVE_URL, timeout=10)
        except Exception as e: 
            print("keepalive error:", e)
        
        await asyncio.sleep(max(60, KEEPALIVE_INTERVAL))

# ================== Startup / Runner ==================
app.state.exchange = None
app.state.exchange_id = EXCHANGE_NAME
app.state.symbols = []
app.state.cycle_count = 0
app.state.last_no_sig_ts = 0

def attempt_build():
    ex, used = try_failover(EXCHANGE_NAME)
    syms = parse_symbols(ex, SYMBOLS_MODE)
    app.state.exchange, app.state.exchange_id, app.state.symbols = ex, used, syms

@app.on_event("startup")
async def _startup():
    db_init()
    
    send_telegram(
        f"ğŸš€ Ø¨ÙˆØª Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¬Ø¨Ø§Ø± v{APP_VERSION}\n"
        f"{'â”' * 30}\n"
        f"âœ… Ø§Ù„Ø¨ÙˆØª ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù†\n"
        f"â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø³ÙˆØ§Ù‚...\n"
        f"ğŸ“Š Timeframe: {TIMEFRAME}\n"
        f"ğŸ’ª ÙˆØ¶Ø¹: Ù…Ø­Ø³Ù‘Ù† ÙˆØ£Ù‚ÙˆÙ‰",
        reply_markup=start_menu_markup()
    )
    
    attempt_build()
    
    syms = app.state.symbols
    ex_id = app.state.exchange_id
    
    head = (
        f"âœ… Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§ÙƒØªÙ…Ù„ Ø¨Ù†Ø¬Ø§Ø­!\n"
        f"{'â”' * 30}\n"
        f"ğŸ“¡ Ø§Ù„Ù…Ù†ØµØ©: {ex_id}\n"
        f"â± Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ: {TIMEFRAME}\n"
        f"ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬: {len(syms)}\n"
        f"ğŸ¯ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø¯Ù†ÙŠØ§: {MIN_CONFIDENCE}%\n"
        f"{'â”' * 30}\n"
        f"Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©:\n"
        f"{', '.join([symbol_pretty(s) for s in syms[:15]])}"
        f"{f'... (+{len(syms)-15} Ø£Ø®Ø±Ù‰)' if len(syms) > 15 else ''}"
    )
    
    send_telegram(head)
    
    asyncio.create_task(runner())
    asyncio.create_task(poll_telegram_commands())
    asyncio.create_task(keepalive_task())

async def maybe_send_no_signal_summary():
    if _last_cycle_alerts > 0: 
        return
    
    now = time.time()
    ok_cycles = (NO_SIG_EVERY_N_CYCLES > 0 and 
                 app.state.cycle_count % NO_SIG_EVERY_N_CYCLES == 0)
    ok_minutes = (NO_SIG_EVERY_MINUTES > 0 and 
                  (now - app.state.last_no_sig_ts) >= NO_SIG_EVERY_MINUTES * 60)
    
    if ok_cycles or ok_minutes:
        send_telegram(
            "â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ ÙØ±Øµ ØªØ¯Ø§ÙˆÙ„ Ù…Ù†Ø§Ø³Ø¨Ø© ÙÙŠ Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©.\n"
            "Ø§Ù„Ø¨ÙˆØª ÙŠØ±Ø§Ù‚Ø¨ Ø§Ù„Ø£Ø³ÙˆØ§Ù‚ Ø¨Ø§Ø³ØªÙ…Ø±Ø§Ø±..."
        )
        app.state.last_no_sig_ts = now

async def runner():
    """Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø¨ÙˆØª"""
    while True:
        try:
            if not app.state.symbols: 
                attempt_build()
            
            await scan_once(app.state.exchange, app.state.symbols)
            app.state.cycle_count += 1
            
            await maybe_send_no_signal_summary()
        
        except Exception as e:
            _error_bucket.append(
                f"Loop: {type(e).__name__} {str(e)}\n"
                f"{traceback.format_exc().splitlines()[-1]}"
            )
        
        await asyncio.sleep(SCAN_INTERVAL)

if __name__ == "__main__":
    port = int(os.getenv("PORT", "10000"))
    uvicorn.run(app, host="0.0.0.0", port=port)
